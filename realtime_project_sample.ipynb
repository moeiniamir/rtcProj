{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import chain, repeat\n",
    "import task_generation.taskset_generation as tg\n",
    "import uuid\n",
    "from enum import Enum\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "id": "BL2xgLByUOTK",
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.822906434Z",
     "start_time": "2023-07-01T22:47:24.792419841Z"
    }
   },
   "execution_count": 192,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task Generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "class PTask:\n",
    "    def __init__(self, period, execution_time):\n",
    "        self.period = period\n",
    "        self.execution_time = execution_time\n",
    "\n",
    "    @property\n",
    "    def utilization(self):\n",
    "        return self.execution_time / self.period\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.period}, {self.execution_time})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.period}, {self.execution_time})\"\n",
    "\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, arrival_time, deadline, execution_time):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.arrival_time = arrival_time\n",
    "        self.deadline = deadline\n",
    "        self.execution_time = execution_time\n",
    "        self.start_time = 0\n",
    "        self.finish_time = 0\n",
    "        self.waiting_time = 0\n",
    "        self.response_time = 0\n",
    "        self.slack_time = 0\n",
    "\n",
    "    @property\n",
    "    def utilization(self):\n",
    "        return self.execution_time / (self.deadline - self.arrival_time)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.arrival_time}, {self.deadline}, {self.execution_time})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.id}, {self.arrival_time}, {self.deadline}, {self.execution_time})\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.922515214Z",
     "start_time": "2023-07-01T22:47:24.798866564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "def generate_ptasks(num_tasks=100, utilization=.5, available_periods=(1, 2, 4, 8, 16)):\n",
    "    \"\"\"\n",
    "    Generates a set of periodic tasks with random periods and costs.\n",
    "    \"\"\"\n",
    "    num_sets = 1\n",
    "    u = np.array(tg.generate_uunifastdiscard(num_sets, utilization, num_tasks, 'test.csv'))\n",
    "    p = np.array(tg.generate_random_periods_discrete(num_tasks, num_sets, available_periods))\n",
    "    tset = np.array(tg.generate_tasksets(u, p, 'tset.csv'), dtype=[('cost', 'float64'), ('period', 'int32')])[0]\n",
    "    tset = [PTask(tset['period'][i], tset['cost'][i]) for i in range(len(tset))]\n",
    "    return tset\n",
    "\n",
    "\n",
    "def generate_tasks(tset):\n",
    "    \"\"\"\n",
    "    Generates a list of tasks from a set of periodic tasks.\n",
    "    \"\"\"\n",
    "    if not tset:\n",
    "        return []\n",
    "    hp = np.lcm.reduce([t.period for t in tset])\n",
    "    tasks = list(chain.from_iterable([\n",
    "        zip(\n",
    "            list(range(0, hp, tset[i].period)),\n",
    "            list(range(tset[i].period, hp + 1, tset[i].period)),\n",
    "            list(repeat(tset[i].execution_time, hp // tset[i].period))\n",
    "        ) for i in range(len(tset))\n",
    "    ]))\n",
    "    # convert tasks to Task objects\n",
    "    tasks = [Task(task[0], task[1], task[2]) for task in tasks]\n",
    "    return tasks\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.945852404Z",
     "start_time": "2023-07-01T22:47:24.819511356Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task Mapping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "class MAPPING_ALGORITHM(Enum):\n",
    "    \"\"\"\n",
    "    An enum representing the mapping algorithm to use.\n",
    "    \"\"\"\n",
    "    FIRST_FIT_DECREASING = 1\n",
    "    BEST_FIT_DECREASING = 2\n",
    "    WORST_FIT_DECREASING = 3\n",
    "    FIRST_FIT_INCREASING = 4\n",
    "    BEST_FIT_INCREASING = 5\n",
    "    WORST_FIT_INCREASING = 6\n",
    "\n",
    "\n",
    "def map_tasks_to_cores(ptasks, num_cores, mapping_algorithm):\n",
    "    \"\"\"\n",
    "    Maps tasks to cores using the specified mapping algorithm.\n",
    "    \"\"\"\n",
    "    # sort tasks based on utilization based on the mapping algorithm\n",
    "    if mapping_algorithm.value <= 3:\n",
    "        ptasks.sort(key=lambda task: task.utilization, reverse=True)\n",
    "    else:\n",
    "        ptasks.sort(key=lambda task: task.utilization, reverse=False)\n",
    "\n",
    "    core_remaining_utilization = [1 / num_cores for _ in range(num_cores)]\n",
    "    core_tasks = [[] for _ in range(num_cores)]\n",
    "\n",
    "    # map tasks to cores\n",
    "    for task in ptasks:\n",
    "        if mapping_algorithm.value % 3 == 1:\n",
    "            # first fit\n",
    "            for i in range(num_cores):\n",
    "                if core_remaining_utilization[i] >= task.utilization:\n",
    "                    core_tasks[i].append(task)\n",
    "                    core_remaining_utilization[i] -= task.utilization\n",
    "                    break\n",
    "            else:\n",
    "                raise Exception('No core has enough remaining utilization to map task.')\n",
    "        elif mapping_algorithm.value % 3 == 2:\n",
    "            # best fit\n",
    "            best_fit = -1\n",
    "            for i in range(num_cores):\n",
    "                if core_remaining_utilization[i] >= task.utilization:\n",
    "                    if best_fit == -1 or core_remaining_utilization[i] < core_remaining_utilization[best_fit]:\n",
    "                        best_fit = i\n",
    "            if best_fit != -1:\n",
    "                core_tasks[best_fit].append(task)\n",
    "                core_remaining_utilization[best_fit] -= task.utilization\n",
    "            else:\n",
    "                raise Exception('No core has enough remaining utilization to map task.')\n",
    "        else:\n",
    "            # worst fit\n",
    "            worst_fit = -1\n",
    "            for i in range(num_cores):\n",
    "                if core_remaining_utilization[i] >= task.utilization:\n",
    "                    if worst_fit == -1 or core_remaining_utilization[i] > core_remaining_utilization[worst_fit]:\n",
    "                        worst_fit = i\n",
    "            if worst_fit != -1:\n",
    "                core_tasks[worst_fit].append(task)\n",
    "                core_remaining_utilization[worst_fit] -= task.utilization\n",
    "            else:\n",
    "                raise Exception('No core has enough remaining utilization to map task.')\n",
    "\n",
    "    return core_tasks\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.946008911Z",
     "start_time": "2023-07-01T22:47:24.860953853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def plot_results(num_tasks_list, ga_results, improved_ga_results):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     x = range(len(num_tasks_list))\n",
    "#     ax.bar(x, ga_results, width=0.3, label=\"GA\")\n",
    "#     ax.bar([i + 0.3 for i in x], improved_ga_results, width=0.3, label=\"Improved GA\")\n",
    "#     ax.set_xticks([i + 0.15 for i in x])\n",
    "#     ax.set_xticklabels(num_tasks_list)\n",
    "#     ax.set_xlabel(\"Number of Tasks\")\n",
    "#     ax.set_ylabel(\"Average Time\")\n",
    "#     ax.set_title(\"Average Times for Different Number of Tasks\")\n",
    "#     ax.legend()\n",
    "\n",
    "#     plt.savefig(\"results.png\")\n",
    "#     plt.show()\n",
    "\n",
    "def write_results_to_file(results, scheduler_name, mapping_name, utilization, num_cores, goals_name):\n",
    "    with open(\"results/\"+\"__\".join([scheduler_name, mapping_name, str(utilization), str(num_cores), goals_name]) + \".json\", \"w\") as file:\n",
    "        json.dump({\"results\": results}, file)\n",
    "\n",
    "def read_results_from_file(scheduler_name, mapping_name, utilization, num_cores, goals_name):\n",
    "    with open(\"results/\"+\"__\".join([scheduler_name, mapping_name, str(utilization), str(num_cores), goals_name]) + \".json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data[\"results\"]\n",
    "\n",
    "def read_tasks_from_file(file_path):\n",
    "    with open(\"inputs/\" + file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    tasks = []\n",
    "    for per_core_tasks_data in data[\"tasks\"]:\n",
    "        per_core_tasks = []\n",
    "        for task_data in per_core_tasks_data:\n",
    "            task = Task(task_data[\"arrival_time\"], task_data[\"deadline\"], task_data[\"execution_time\"])\n",
    "            per_core_tasks.append(task)\n",
    "        tasks.append(per_core_tasks)\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def write_tasks_to_file(tasks):\n",
    "    file_name = uuid.uuid4().hex + \".json\"\n",
    "    with open(\"inputs/\" + file_name, \"w\") as file:\n",
    "        json.dump({\"tasks\": [[{\n",
    "            \"arrival_time\": task.arrival_time,\n",
    "            \"deadline\": task.deadline,\n",
    "            \"execution_time\": task.execution_time\n",
    "        } for task in taskset] for taskset in tasks]}, file)\n",
    "    return file_name\n",
    "\n",
    "class GOAL(Enum):\n",
    "    \"\"\"\n",
    "    An enum representing the goal to optimize.\n",
    "    \"\"\"\n",
    "    COMPLETION_TIME = 1\n",
    "    LATENESS = 2\n",
    "    WAIT_TIME = 3\n",
    "    RESP_TIME = 4\n",
    "    SLACK_TIME = 5\n",
    "\n",
    "def calc_goal_val(goals, final_time, avg_lateness, avg_wait_time, avg_resp_time, avg_slack_time):\n",
    "    val = 0\n",
    "    if GOAL.COMPLETION_TIME in goals:\n",
    "        val += final_time\n",
    "    if GOAL.LATENESS in goals:\n",
    "        val += avg_lateness\n",
    "    if GOAL.WAIT_TIME in goals:\n",
    "        val += avg_wait_time\n",
    "    if GOAL.RESP_TIME in goals:\n",
    "        val += avg_resp_time\n",
    "    if GOAL.SLACK_TIME in goals:\n",
    "        val += avg_slack_time\n",
    "    return val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.946301138Z",
     "start_time": "2023-07-01T22:47:24.861314216Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PSO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self):\n",
    "        self._order = None\n",
    "        self.best = None\n",
    "        self.fitness = None\n",
    "        self.final_time = None\n",
    "        self.avg_lateness = None\n",
    "        self.avg_wait_time = None\n",
    "        self.avg_resp_time = None\n",
    "        self.avg_slack_time = None\n",
    "\n",
    "    def set_order(self, order):\n",
    "        self._order = order\n",
    "        return self\n",
    "\n",
    "    def get_order(self):\n",
    "        return self._order\n",
    "\n",
    "    def save_if_better(self, particle):\n",
    "        if self.best is None or (self.best.fitness < particle.fitness and\n",
    "                                 ((self.best.avg_lateness > 0) or (particle.avg_lateness == 0))):\n",
    "            self.best = particle.copy()\n",
    "\n",
    "    def copy(self):\n",
    "        particle = Particle()\n",
    "        particle.set_order(self._order.copy())\n",
    "        particle.fitness = self.fitness\n",
    "        particle.final_time = self.final_time\n",
    "        particle.avg_lateness = self.avg_lateness\n",
    "        particle.avg_wait_time = self.avg_wait_time\n",
    "        particle.avg_resp_time = self.avg_resp_time\n",
    "        particle.avg_slack_time = self.avg_slack_time\n",
    "        return particle\n",
    "\n",
    "\n",
    "class PSOScheduler:\n",
    "    def __init__(self, w, c1, c2, tasks, goal):\n",
    "        self.particles, self.particle_count = None, None\n",
    "        self.best_keeper = Particle()\n",
    "        self.tasks = tasks\n",
    "        self.w, self.c1, self.c2 = w, c1, c2\n",
    "        self.goal = goal\n",
    "\n",
    "    def calculate_fitness(self, particle):\n",
    "        final_time, avg_wait_time, avg_resp_time, avg_lateness, avg_slack_time = self.evaluate(particle.get_order())\n",
    "        # fitness = -(100*self.sigmoid(avg_lateness)**(1/10) + self.sigmoid(avg_resp_time + avg_wait_time))\n",
    "        fitness = 1 / (10*np.exp(avg_lateness*10) + calc_goal_val(\n",
    "            self.goal, final_time, avg_lateness, avg_wait_time, avg_resp_time, avg_slack_time))\n",
    "        # fitness = 1/(np.exp(avg_lateness*10 + avg_resp_time + avg_wait_time))\n",
    "\n",
    "        particle.fitness, particle.avg_lateness, particle.avg_wait_time, particle.avg_resp_time, particle.avg_slack_time, particle.final_time = fitness, avg_lateness, avg_wait_time, avg_resp_time, avg_slack_time, final_time\n",
    "        particle.save_if_better(particle)\n",
    "\n",
    "    def evaluate(self, order):\n",
    "        \"\"\"\n",
    "        Evaluates an order by simulating the execution of the tasks.\n",
    "\n",
    "        Args:\n",
    "            order (list): A list representing the order of tasks to be executed.\n",
    "        Returns:\n",
    "            tuple: A tuple containing the full time, final time, wait time, response time, and slack time.\n",
    "        \"\"\"\n",
    "        final_time = 0\n",
    "        wait_time = 0\n",
    "        resp_time = 0\n",
    "        lateness = 0\n",
    "        slack_time = 0\n",
    "\n",
    "        for task_id in order:\n",
    "            task = self.tasks[task_id]\n",
    "            task.start_time = max(task.arrival_time, final_time)\n",
    "            task.finish_time = task.start_time + task.execution_time\n",
    "            task.waiting_time = task.start_time - task.arrival_time\n",
    "            task.response_time = task.finish_time - task.arrival_time\n",
    "            task.lateness = task.finish_time - task.deadline\n",
    "            task.slack_time = task.start_time - final_time\n",
    "\n",
    "            final_time = task.finish_time\n",
    "            wait_time += task.waiting_time\n",
    "            resp_time += task.response_time\n",
    "            lateness += max(0, task.lateness)\n",
    "            slack_time += task.slack_time\n",
    "\n",
    "        return final_time, wait_time/len(order), resp_time/len(order), lateness/len(order), slack_time/len(order)\n",
    "\n",
    "    def initiate_swarm(self, particle_count):\n",
    "        self.particle_count = particle_count\n",
    "        self.particles = []\n",
    "        for _ in range(self.particle_count):\n",
    "            order = list(range(len(self.tasks)))\n",
    "            random.shuffle(order)\n",
    "            particle = Particle()\n",
    "            particle.set_order(order)\n",
    "            self.calculate_fitness(particle)\n",
    "            self.best_keeper.save_if_better(particle.best)\n",
    "            self.particles.append(particle)\n",
    "\n",
    "    def move_particles(self):\n",
    "        for particle in self.particles:\n",
    "            self.local_search(particle)  # M1\n",
    "            self.path_relinking(particle, self.best_keeper.best.get_order(), self.c2)  # M3\n",
    "            self.path_relinking(particle, particle.best.get_order(), self.c1)  # M2\n",
    "\n",
    "    def local_search(self, particle):\n",
    "        \"\"\"\n",
    "        insert some of the tasks with the highest lateness in the first position after its release time\n",
    "        \"\"\"\n",
    "        steps = int(len(self.tasks) / 10 * self.w)\n",
    "        # steps = int(len(self.tasks) / 10 * random.uniform(.2, 1))\n",
    "        if steps == 0:\n",
    "            steps = 1\n",
    "\n",
    "        x = particle.get_order()\n",
    "        self.evaluate(x) # O(n)\n",
    "        lateness = [(self.tasks[task_id].lateness, task_id) for task_id in x] # O(n)\n",
    "        tasks_to_move = [task_id for _, task_id in sorted(lateness, reverse=True)[:steps]] # O(nlogn)\n",
    "        arrival_times = [(self.tasks[task_id].arrival_time, task_id) for task_id in tasks_to_move]\n",
    "        arrival_times.sort() # O(nlogn)\n",
    "        arrival_index = 0\n",
    "        task_id_to_order = {task_id: i for i, task_id in enumerate(x)}\n",
    "        for task_id in x:\n",
    "            if self.tasks[task_id].start_time > arrival_times[arrival_index][0]:\n",
    "                task_to_move = arrival_times[arrival_index][1]\n",
    "                task_id_to_order[task_to_move] = task_id_to_order[task_id] - .5\n",
    "                arrival_index += 1\n",
    "                if arrival_index == len(arrival_times):\n",
    "                    break\n",
    "        x = [task_id for task_id, _ in sorted(task_id_to_order.items(), key=lambda xx: xx[1])]\n",
    "        particle.set_order(x)\n",
    "        self.calculate_fitness(particle) # O(n)\n",
    "        self.best_keeper.save_if_better(particle.best)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_distance(x, y):\n",
    "        \"\"\"\n",
    "        Calculates the distance between two orders. i.e. the minimum number of swaps required to transform one order into the other.\n",
    "        \"\"\"\n",
    "        x = x.copy()\n",
    "        x_to_index = {task_id: i for i, task_id in enumerate(x)}\n",
    "        swap_count = 0\n",
    "        for i in range(len(x)):\n",
    "            if x[i] != y[i]:\n",
    "                swap_count += 1\n",
    "                j = x_to_index[y[i]]\n",
    "                x[i], x[j] = x[j], x[i]\n",
    "                x_to_index[x[i]], x_to_index[x[j]] = x_to_index[x[j]], x_to_index[x[i]]\n",
    "        return swap_count\n",
    "\n",
    "    def path_relinking(self, particle, t, c):\n",
    "        x = particle.get_order()\n",
    "        max_distance = self.calculate_distance(x, t)\n",
    "        phi = np.random.uniform(0, 1)\n",
    "        steps = int((phi + c) / 2 * max_distance)\n",
    "        x_to_index = {task_id: i for i, task_id in enumerate(x)}\n",
    "\n",
    "        unequal_indices = [i for i in range(len(x)) if x[i] != t[i]]\n",
    "        np.random.shuffle(unequal_indices)\n",
    "        random_indices = unequal_indices[:steps]\n",
    "        for step in range(steps):\n",
    "            i = random_indices[step]\n",
    "            j = x_to_index[t[i]]\n",
    "            x[i], x[j] = x[j], x[i]\n",
    "            x_to_index[x[i]], x_to_index[x[j]] = x_to_index[x[j]], x_to_index[x[i]]\n",
    "        particle.set_order(x)\n",
    "        self.calculate_fitness(particle)\n",
    "        self.best_keeper.save_if_better(particle.best)\n",
    "\n",
    "    def check_for_convergence(self):\n",
    "        for i in range(1, len(self.particles)):\n",
    "            particle0 = self.particles[i-1]\n",
    "            particle1 = self.particles[i]\n",
    "            if np.any(np.array(particle0.get_order()) != np.array(particle1.get_order())):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def run(self, max_iterations):\n",
    "        for i in tqdm(range(max_iterations)):\n",
    "            # print(f\"iteration {i}\")\n",
    "            self.move_particles()\n",
    "\n",
    "            # print(f\"ftime: {self.best_keeper.best.final_time:.4f}, avgwtime: {self.best_keeper.best.avg_wait_time:.4f}, avgrtime: {self.best_keeper.best.avg_resp_time:.4f}, avgstime: {self.best_keeper.best.avg_slack_time:.4f} avgl: {self.best_keeper.best.avg_lateness:.4f}\")\n",
    "\n",
    "            self.w -= (self.w - .01)/(max_iterations - i)*2\n",
    "            # if self.check_for_convergence():\n",
    "            #     break\n",
    "        return self.best_keeper.best\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.946347721Z",
     "start_time": "2023-07-01T22:47:24.891677879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "def single_set_pso(tasks, goal):\n",
    "    pso = PSOScheduler(.9, 0.8, 0.5, tasks, goal)\n",
    "    pso.initiate_swarm(20)\n",
    "    best = pso.run(1000)\n",
    "    pso.evaluate(best.get_order())\n",
    "    return {\n",
    "        'order': best.get_order(),\n",
    "        'fitness': best.fitness,\n",
    "        'final_time': best.final_time,\n",
    "        'avg_wait_time': best.avg_wait_time,\n",
    "        'avg_resp_time': best.avg_resp_time,\n",
    "        'avg_lateness': best.avg_lateness,\n",
    "        'avg_slack_time': best.avg_slack_time,\n",
    "        'slack_between': [task.slack_time for task in tasks],\n",
    "        'lateness_per_task': [max(0, task.lateness) for task in tasks],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.955431739Z",
     "start_time": "2023-07-01T22:47:24.922358965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "def pso(tasks, goal):\n",
    "    process_pool = ProcessPoolExecutor(max_workers=len(tasks))\n",
    "    futures = [process_pool.submit(single_set_pso, tasks[i], goal) for i in range(len(tasks))]\n",
    "    results = [future.result() for future in futures]\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:24.978796285Z",
     "start_time": "2023-07-01T22:47:24.950771522Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    def __init__(self, num_tasks, mutation_rate, crossover_rate, max_iter):\n",
    "        self.num_tasks = num_tasks\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.population = []\n",
    "        self.best_fitness = 0\n",
    "        self.best_chromosome = []\n",
    "\n",
    "    def initialize(self):\n",
    "        # code to initialize population with random chromosomes\n",
    "        pass\n",
    "\n",
    "    def crossover(self):\n",
    "        # code to perform crossover between parent chromosomes\n",
    "        pass\n",
    "\n",
    "    def mutate(self):\n",
    "        # code to perform mutation on child chromosomes\n",
    "        pass\n",
    "\n",
    "    def fitness(self):\n",
    "        # code to calculate fitness of each chromosome in the population\n",
    "        pass\n",
    "\n",
    "    def selection(self):\n",
    "        # code to perform selection of fittest chromosomes for next generation\n",
    "        pass\n",
    "\n",
    "    def evolve(self, num_generations):\n",
    "        # code to run GA algorithm for given number of generations\n",
    "        pass\n",
    "\n",
    "    def run(self, tasks):\n",
    "        # code to run the scheduler for given tasks using GA algorithm\n",
    "        pass\n",
    "\n",
    "class GA_Scheduler(Scheduler):\n",
    "    \"\"\"\n",
    "    A class representing the GA algorithm for task scheduling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_tasks, mutation_rate, crossover_rate, max_iter, pop_size, goal):\n",
    "        super().__init__(num_tasks, mutation_rate, crossover_rate, max_iter)\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.goal = goal\n",
    "\n",
    "    def initialize_population(self, num_tasks):\n",
    "        \"\"\"\n",
    "        Initializes the population with random task orders.\n",
    "\n",
    "        Args:\n",
    "            num_tasks (int): Number of tasks.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of task orders (chromosomes).\n",
    "        \"\"\"\n",
    "        population = []\n",
    "        for i in range(self.pop_size):\n",
    "            chromosome = [j for j in range(num_tasks)]\n",
    "            random.shuffle(chromosome)\n",
    "            population.append(chromosome)\n",
    "        return population\n",
    "\n",
    "    def calculate_fitness(self, population, tasks):\n",
    "        \"\"\"\n",
    "        Calculates the fitness of each chromosome in the population.\n",
    "\n",
    "        Args:\n",
    "            population (list): A list of task orders (chromosomes).\n",
    "            tasks (list): A list of Task objects.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tuples containing the chromosome and its fitness.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        fitness_scores = []\n",
    "        for chromosome in population:\n",
    "            final_time, wait_time, resp_time, lateness, slack_time = self.evaluate(chromosome, tasks)\n",
    "            # fitness = 1 / (1 + slack_time)\n",
    "            # fitness = 100 * slack_time\n",
    "            # fitness = 1 / (np.exp(lateness*10 + resp_time/10 + wait_time/10))\n",
    "            fitness = 1 / (10*np.exp(lateness*10) + calc_goal_val(\n",
    "                self.goal, final_time, wait_time, resp_time, lateness, slack_time))\n",
    "            if lateness == 0:\n",
    "                fitness *= 2\n",
    "            fitness_scores.append((chromosome, fitness))\n",
    "            # print(f\"ftime: {final_time:.4f}, wtime: {wait_time:.4f}, rtime: {resp_time:.4f}, l: {lateness:.4f} fitness: {fitness:.4f} \", chromosome)\n",
    "        return fitness_scores\n",
    "\n",
    "    def evaluate(self, chromosome, tasks):\n",
    "        \"\"\"\n",
    "        Evaluates a chromosome by simulating the execution of the tasks.\n",
    "\n",
    "        Args:\n",
    "            chromosome (list): A list representing the order of tasks to be executed.\n",
    "            tasks (list): A list of Task objects.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the full time, final time, wait time, response time, and slack time.\n",
    "        \"\"\"\n",
    "        final_time = 0\n",
    "        wait_time = 0\n",
    "        resp_time = 0\n",
    "        lateness = 0\n",
    "        slack_time = 0\n",
    "\n",
    "\n",
    "        task_copy = tasks.copy()\n",
    "        # task_copy.sort(key=lambda x: x.arrival_time)\n",
    "\n",
    "        s_time = []\n",
    "\n",
    "        for task_id in chromosome:\n",
    "            task = task_copy[task_id]\n",
    "            task.start_time = max(task.arrival_time, final_time)\n",
    "            task.finish_time = task.start_time + task.execution_time\n",
    "            task.waiting_time = task.start_time - task.arrival_time\n",
    "            task.response_time = task.finish_time - task.arrival_time\n",
    "            task.lateness = task.finish_time - task.deadline\n",
    "            task.slack_time = task.start_time - final_time\n",
    "\n",
    "            final_time = task.finish_time\n",
    "            wait_time += task.waiting_time\n",
    "            resp_time += task.response_time\n",
    "            lateness += max(0, task.lateness)\n",
    "            slack_time += task.slack_time\n",
    "            # s_time.append(task.lateness)\n",
    "\n",
    "        return final_time, wait_time/len(tasks), resp_time/len(tasks), lateness/len(tasks), slack_time/len(tasks)\n",
    "\n",
    "    def selection_old(self, fitness_scores):\n",
    "        \"\"\"\n",
    "        Selects two parent chromosomes using tournament selection.\n",
    "\n",
    "        Args:\n",
    "            fitness_scores (list): A list of tuples containing the chromosome and its fitness.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the two parent chromosomes.\n",
    "        \"\"\"\n",
    "        # candidates = random.sample(fitness_scores, 2)\n",
    "\n",
    "        candidates1 = max(fitness_scores, key=lambda x: x[1])\n",
    "        fitness_scores_copy = fitness_scores.copy()\n",
    "        fitness_scores_copy.remove(candidates1)\n",
    "        candidates2 = max(fitness_scores_copy, key=lambda x: x[1])\n",
    "        for _ in range(len(fitness_scores)):\n",
    "            if candidates1 == candidates2:\n",
    "                fitness_scores_copy.remove(candidates2)\n",
    "            candidates2 = max(fitness_scores_copy, key=lambda x: x[1])\n",
    "            if len(fitness_scores_copy) < 2:\n",
    "                break\n",
    "        # parent1 = max(candidates, key=lambda x: x[1])[0]\n",
    "\n",
    "        # candidates = random.sample(fitness_scores, 2)\n",
    "        # parent2 = max(candidates, key=lambda x: x[1])[0]\n",
    "\n",
    "        return candidates1[0], candidates2[0]\n",
    "\n",
    "    def selection(self, fitness_scores):\n",
    "        \"\"\"\n",
    "        Selects two parent chromosomes using tournament selection.\n",
    "\n",
    "        Args:\n",
    "            fitness_scores (list): A list of tuples containing the chromosome and its fitness.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the two parent chromosomes.\n",
    "        \"\"\"\n",
    "        # generate two random integers with weights based on fitness\n",
    "        weights = [x[1] for x in fitness_scores]\n",
    "        # normalize weights\n",
    "        sum_weights = sum(weights)\n",
    "        weights = [x/sum_weights for x in weights]\n",
    "        index1, index2 = random.choices(range(len(fitness_scores)), weights=weights, k=2)\n",
    "        candidates1 = fitness_scores[index1]\n",
    "        candidates2 = fitness_scores[index2]\n",
    "\n",
    "        return candidates1[0], candidates2[0]\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        \"\"\"\n",
    "        Performs crossover between two parent chromosomes.\n",
    "\n",
    "        Args:\n",
    "            parent1 (list): The first parent chromosome.\n",
    "            parent2 (list): The second parent chromosome.\n",
    "\n",
    "        Returns:\n",
    "            list: The child chromosome resulting from crossover.\n",
    "        \"\"\"\n",
    "        crossover_point = random.randint(1, len(parent1) - 1)\n",
    "        child = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "\n",
    "        return child\n",
    "\n",
    "    def pbc_crossover(self, parent1, parent2):\n",
    "        \"\"\"\n",
    "        Perform position-based crossover (PBC) on two parent chromosomes to create a new child chromosome.\n",
    "\n",
    "        Parameters:\n",
    "            parent1 (list): The first parent chromosome.\n",
    "            parent2 (list): The second parent chromosome.\n",
    "\n",
    "        Returns:\n",
    "            list: The new child chromosome.\n",
    "        \"\"\"\n",
    "        n = len(parent1)\n",
    "        child = [-1] * n\n",
    "        # Select random positions for the crossover points\n",
    "        positions = sorted(random.sample(range(n), 2))\n",
    "        # Copy the genetic material from the parents into the child chromosome\n",
    "        for i in range(positions[0], positions[1]):\n",
    "            child[i] = parent1[i]\n",
    "        # Fill in the remaining positions in the child chromosome with genetic material from the second parent\n",
    "        fast_child = set(child)\n",
    "        j = 0\n",
    "        for i in range(n):\n",
    "            if not parent2[i] in fast_child:\n",
    "                while child[j] != -1:\n",
    "                    j += 1\n",
    "                child[j] = parent2[i]\n",
    "        return child\n",
    "\n",
    "    def ox_crossover(self, parent1, parent2):\n",
    "        \"\"\"\n",
    "        Perform order crossover (OX) on two parent chromosomes to create a new child chromosome.\n",
    "\n",
    "        Parameters:\n",
    "            parent1 (list): The first parent chromosome.\n",
    "            parent2 (list): The second parent chromosome.\n",
    "\n",
    "        Returns:\n",
    "            list: The new child chromosome.\n",
    "        \"\"\"\n",
    "        n = len(parent1)\n",
    "        child = [-1] * n\n",
    "\n",
    "        # Select two random positions for the crossover points\n",
    "        positions = sorted(random.sample(range(n), 2))\n",
    "\n",
    "        # Copy genetic material from the first parent into the child chromosome between the crossover points\n",
    "        child[positions[0]:positions[1]] = parent1[positions[0]:positions[1]]\n",
    "\n",
    "        # Fill in the remaining positions in the child chromosome with genetic material from the second parent\n",
    "        j = positions[1]\n",
    "        for i in range(n):\n",
    "            if not parent2[i] in child:\n",
    "                if j == n:\n",
    "                    j = 0\n",
    "                child[j] = parent2[i]\n",
    "                j += 1\n",
    "\n",
    "        return child\n",
    "\n",
    "    def mutate(self, chromosome):\n",
    "        \"\"\"\n",
    "        Mutates a chromosome.\n",
    "\n",
    "        Args:\n",
    "            chromosome (list): The chromosome to mutate.\n",
    "\n",
    "        Returns:\n",
    "            list: The mutated chromosome.\n",
    "        \"\"\"\n",
    "        if random.random() < self.mutation_rate:\n",
    "            idx1, idx2 = random.sample(range(len(chromosome)), 2)\n",
    "            chromosome[idx1], chromosome[idx2] = chromosome[idx2], chromosome[idx1]\n",
    "\n",
    "        return chromosome\n",
    "\n",
    "    def smart_mutate(self, chromosome):\n",
    "        x = chromosome\n",
    "        steps = int(len(self.tasks)/10 * random.uniform(.2, 1))\n",
    "        if steps == 0:\n",
    "            steps = 1\n",
    "        self.evaluate(x, self.tasks) # O(n)\n",
    "        lateness = [(self.tasks[task_id].lateness, task_id) for task_id in x] # O(n)\n",
    "        tasks_to_move = [task_id for _, task_id in sorted(lateness, reverse=True)[:steps]] # O(nlogn)\n",
    "        arrival_times = [(self.tasks[task_id].arrival_time, task_id) for task_id in tasks_to_move]\n",
    "        arrival_times.sort() # O(nlogn)\n",
    "        arrival_index = 0\n",
    "        task_id_to_order = {task_id: i for i, task_id in enumerate(x)}\n",
    "        for task_id in x:\n",
    "            if self.tasks[task_id].start_time > arrival_times[arrival_index][0]:\n",
    "                task_to_move = arrival_times[arrival_index][1]\n",
    "                task_id_to_order[task_to_move] = task_id_to_order[task_id] - .5\n",
    "                arrival_index += 1\n",
    "                if arrival_index == len(arrival_times):\n",
    "                    break\n",
    "        x = [task_id for task_id, _ in sorted(task_id_to_order.items(), key=lambda x: x[1])]\n",
    "        return x\n",
    "\n",
    "    def evolve(self, population, fitness_scores):\n",
    "        \"\"\"\n",
    "        Evolves the population by selecting parents, performing crossover and mutation, and generating a new population.\n",
    "\n",
    "        Args:\n",
    "            population (list): A list of task orders (chromosomes).\n",
    "            fitness_scores (list): A list of tuples containing the chromosome and its fitness.\n",
    "\n",
    "        Returns:\n",
    "            list: A new list of task orders (chromosomes).\n",
    "        \"\"\"\n",
    "        new_population = []\n",
    "\n",
    "        for _ in range(len(population)):\n",
    "            parent1, parent2 = self.selection(fitness_scores)\n",
    "            # child = self.ox_crossover(parent1, parent2)\n",
    "            child = self.pbc_crossover(parent1, parent2)\n",
    "            # child = self.mutate(child)\n",
    "            child = self.smart_mutate(child)\n",
    "            new_population.append(child)\n",
    "\n",
    "        return new_population\n",
    "\n",
    "    def run(self, tasks):\n",
    "        \"\"\"\n",
    "        Runs the GA\n",
    "\n",
    "        \"\"\"\n",
    "        population = self.initialize_population(self.num_tasks)\n",
    "        self.tasks = tasks\n",
    "\n",
    "        best_ever_chromosome, best_ever_fitness, best_ever_lateness = None, None, None\n",
    "        for i in tqdm(range(self.max_iter)):\n",
    "            # print(\"Iteration: \", i)\n",
    "            fitness_scores = self.calculate_fitness(population, tasks)\n",
    "            population = self.evolve(population, fitness_scores)\n",
    "            best_chromosome, best_fitness = max(fitness_scores, key=lambda x: x[1])\n",
    "            final_time, avg_wait_time, avg_resp_time, avg_lateness, avg_slack_time = self.evaluate(best_chromosome, tasks)\n",
    "            # print(f\"ft: {final_time}, avgwt: {avg_wait_time}, avgrt: {avg_resp_time}, avgl: {avg_lateness}\")\n",
    "\n",
    "            if best_ever_fitness is None or (best_fitness > best_ever_fitness and ((best_ever_lateness > 0) or (avg_lateness == 0))):\n",
    "                best_ever_chromosome = best_chromosome\n",
    "                best_ever_fitness = best_fitness\n",
    "                best_ever_lateness = avg_lateness\n",
    "\n",
    "            self.mutation_rate -= (self.mutation_rate - 0.1) / (self.max_iter - i) * 1.5\n",
    "        return best_ever_chromosome, best_ever_fitness, best_ever_lateness\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:25.016745796Z",
     "start_time": "2023-07-01T22:47:24.978933103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "def single_set_ga(tasks, goal):\n",
    "    num_tasks = len(tasks)\n",
    "    ga = GA_Scheduler(num_tasks, 0.8, 0.9, 1000, 100, goal)\n",
    "    best_chromosome, best_fitness, best_lateness = ga.run(tasks)\n",
    "\n",
    "    final_time, avg_wait_time, avg_resp_time, avg_lateness, avg_slack_time = ga.evaluate(best_chromosome, tasks)\n",
    "    # print(f\"fit: {best_fitness} ft: {final_time}, avgwt: {avg_wait_time}, avgrt: {avg_resp_time}, avgst: {avg_slack_time} avgl: {avg_lateness}\")\n",
    "\n",
    "    return {\n",
    "        'order': best_chromosome,\n",
    "        'fitness': best_fitness,\n",
    "        'avg_lateness': avg_lateness,\n",
    "        'avg_wait_time': avg_wait_time,\n",
    "        'avg_resp_time': avg_resp_time,\n",
    "        'avg_slack_time': avg_slack_time,\n",
    "        'final_time': final_time,\n",
    "        'slack_between': [task.slack_time for task in tasks],\n",
    "        'lateness_per_task': [max(0, task.lateness) for task in tasks],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:25.040385980Z",
     "start_time": "2023-07-01T22:47:25.012023607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "def ga(tasks, goal):\n",
    "    process_pool = ProcessPoolExecutor(max_workers=len(tasks))\n",
    "    futures = [process_pool.submit(single_set_ga, tasks[i], goal) for i in range(len(tasks))]\n",
    "    results = [future.result() for future in futures]\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:25.082274868Z",
     "start_time": "2023-07-01T22:47:25.038023066Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "# def main(scheduler, mapping, utilization, num_cores, goal):\n",
    "#     num_repeats = 10\n",
    "#     result = {\n",
    "#         \"input_files\": [],\n",
    "#\n",
    "#         \"utilization\": utilization,\n",
    "#         \"scheduling_alg\": scheduler.__name__,\n",
    "#         \"mapping_alg\": mapping.name,\n",
    "#         \"num_cores\": num_cores,\n",
    "#         \"goal\": [g.name for g in goal],\n",
    "#\n",
    "#         \"order\": [], # order of tasks. per core.\n",
    "#         \"final_time\": [], # max final time over all cores\n",
    "#         \"avg_final_time\": 0,\n",
    "#         \"waiting_time\": [], # sum of waiting times of all tasks\n",
    "#         \"avg_waiting_time\": 0,\n",
    "#         \"response_time\": [], # sum of response times of all tasks\n",
    "#         \"avg_response_time\": 0,\n",
    "#         \"slack_time\": [], # sum of slack times of all tasks\n",
    "#         \"lateness\": [], # sum of lateness of all tasks\n",
    "#         \"slack_between\": [], # slack before each task. per core.\n",
    "#         \"lateness_per_task\": [], # lateness of each task. per core.\n",
    "#         \"convergence_time\": [], # max exec time of all cores' schedulers\n",
    "#     }\n",
    "#     for i in range(num_repeats):\n",
    "#         ptasks = generate_ptasks(100, utilization=utilization)\n",
    "#         mapped_tasks = map_tasks_to_cores(ptasks, num_cores, mapping)\n",
    "#         tasks = [generate_tasks(tset) for tset in mapped_tasks]\n",
    "#         input_file = write_tasks_to_file(tasks)\n",
    "#\n",
    "#         time_start = time.time()\n",
    "#         results = scheduler(tasks, goal)\n",
    "#         time_end = time.time()\n",
    "#         convergence_time = time_end - time_start\n",
    "#\n",
    "#         order = [result['order'] for result in results]\n",
    "#         final_time = max([result['final_time'] for result in results])\n",
    "#         waiting_time = sum([result['avg_wait_time']*len(result['order']) for result in results])\n",
    "#         response_time = sum([result['avg_resp_time']*len(result['order']) for result in results])\n",
    "#         slack_time = sum([result['avg_slack_time']*len(result['order']) for result in results])\n",
    "#         lateness = sum([result['avg_lateness']*len(result['order']) for result in results])\n",
    "#         slack_between = [result['slack_between'] for result in results]\n",
    "#         lateness_per_task = [result['lateness_per_task'] for result in results]\n",
    "#\n",
    "#         result['input_files'].append(input_file)\n",
    "#         result['order'].append(order)\n",
    "#         result['final_time'].append(final_time)\n",
    "#         result['waiting_time'].append(waiting_time)\n",
    "#         result['response_time'].append(response_time)\n",
    "#         result['slack_time'].append(slack_time)\n",
    "#         result['lateness'].append(lateness)\n",
    "#         result['slack_between'].append(slack_between)\n",
    "#         result['lateness_per_task'].append(lateness_per_task)\n",
    "#         result['convergence_time'].append(convergence_time)\n",
    "#\n",
    "#     result['avg_final_time'] = sum(result['final_time']) / num_repeats\n",
    "#     result['avg_waiting_time'] = sum(result['waiting_time']) / num_repeats\n",
    "#     result['avg_response_time'] = sum(result['response_time']) / num_repeats\n",
    "#\n",
    "#     return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:25.116597965Z",
     "start_time": "2023-07-01T22:47:25.067106572Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "def one_trial(scheduler, mapping, utilization, num_cores, goal):\n",
    "    ptasks = generate_ptasks(100, utilization=utilization)\n",
    "    mapped_tasks = map_tasks_to_cores(ptasks, num_cores, mapping)\n",
    "    tasks = [generate_tasks(tset) for tset in mapped_tasks]\n",
    "    input_file = write_tasks_to_file(tasks)\n",
    "\n",
    "    time_start = time.time()\n",
    "    results = scheduler(tasks, goal)\n",
    "    time_end = time.time()\n",
    "    convergence_time = time_end - time_start\n",
    "\n",
    "    order = [result['order'] for result in results]\n",
    "    final_time = max([result['final_time'] for result in results])\n",
    "    waiting_time = sum([result['avg_wait_time']*len(result['order']) for result in results])\n",
    "    response_time = sum([result['avg_resp_time']*len(result['order']) for result in results])\n",
    "    slack_time = sum([result['avg_slack_time']*len(result['order']) for result in results])\n",
    "    lateness = sum([result['avg_lateness']*len(result['order']) for result in results])\n",
    "    slack_between = [result['slack_between'] for result in results]\n",
    "    lateness_per_task = [result['lateness_per_task'] for result in results]\n",
    "\n",
    "    return {\n",
    "        'input_file': input_file,\n",
    "        'order': order,\n",
    "        'final_time': final_time,\n",
    "        'waiting_time': waiting_time,\n",
    "        'response_time': response_time,\n",
    "        'slack_time': slack_time,\n",
    "        'lateness': lateness,\n",
    "        'slack_between': slack_between,\n",
    "        'lateness_per_task': lateness_per_task,\n",
    "        'convergence_time': convergence_time,\n",
    "    }\n",
    "\n",
    "def main(scheduler, mapping, utilization, num_cores, goal):\n",
    "    num_repeats = 10\n",
    "    result = {\n",
    "        \"input_files\": [],\n",
    "\n",
    "        \"utilization\": utilization,\n",
    "        \"scheduling_alg\": scheduler.__name__,\n",
    "        \"mapping_alg\": mapping.name,\n",
    "        \"num_cores\": num_cores,\n",
    "        \"goal\": [g.name for g in goal],\n",
    "\n",
    "        \"order\": [], # order of tasks. per core.\n",
    "        \"final_time\": [], # max final time over all cores\n",
    "        \"avg_final_time\": 0,\n",
    "        \"waiting_time\": [], # sum of waiting times of all tasks\n",
    "        \"avg_waiting_time\": 0,\n",
    "        \"response_time\": [], # sum of response times of all tasks\n",
    "        \"avg_response_time\": 0,\n",
    "        \"slack_time\": [], # sum of slack times of all tasks\n",
    "        \"lateness\": [], # sum of lateness of all tasks\n",
    "        \"slack_between\": [], # slack before each task. per core.\n",
    "        \"lateness_per_task\": [], # lateness of each task. per core.\n",
    "        \"convergence_time\": [], # max exec time of all cores' schedulers\n",
    "    }\n",
    "\n",
    "    process_pool = ProcessPoolExecutor(max_workers=num_repeats)\n",
    "    futures = [process_pool.submit(one_trial, scheduler, mapping, utilization, num_cores, goal) for _ in range(num_repeats)]\n",
    "    results = [future.result() for future in futures]\n",
    "    for res in results:\n",
    "        result['input_files'].append(res['input_file'])\n",
    "        result['order'].append(res['order'])\n",
    "        result['final_time'].append(res['final_time'])\n",
    "        result['waiting_time'].append(res['waiting_time'])\n",
    "        result['response_time'].append(res['response_time'])\n",
    "        result['slack_time'].append(res['slack_time'])\n",
    "        result['lateness'].append(res['lateness'])\n",
    "        result['slack_between'].append(res['slack_between'])\n",
    "        result['lateness_per_task'].append(res['lateness_per_task'])\n",
    "        result['convergence_time'].append(res['convergence_time'])\n",
    "\n",
    "    result['avg_final_time'] = sum(result['final_time']) / num_repeats\n",
    "    result['avg_waiting_time'] = sum(result['waiting_time']) / num_repeats\n",
    "    result['avg_response_time'] = sum(result['response_time']) / num_repeats\n",
    "\n",
    "    write_results_to_file(result, scheduler.__name__, mapping.name, utilization, num_cores, '_'.join([g.name for g in goal]))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:47:25.116803705Z",
     "start_time": "2023-07-01T22:47:25.113053189Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 635/1000 [01:12<00:28, 12.63it/s]]\n",
      " 77%|███████▋  | 771/1000 [01:14<00:24,  9.42it/s]]\n",
      " 70%|██████▉   | 695/1000 [01:15<00:36,  8.29it/s]]\n",
      " 98%|█████████▊| 982/1000 [01:29<00:01, 10.51it/s]]\n",
      " 77%|███████▋  | 769/1000 [01:30<00:23,  9.71it/s]]\n",
      " 72%|███████▏  | 716/1000 [01:32<00:38,  7.39it/s]]\n",
      " 87%|████████▋ | 867/1000 [01:32<00:12, 10.45it/s]]\n",
      " 73%|███████▎  | 732/1000 [01:33<00:28,  9.49it/s]]\n",
      " 63%|██████▎   | 633/1000 [01:34<00:38,  9.50it/s]]\n",
      " 93%|█████████▎| 932/1000 [01:34<00:06, 10.62it/s]]\n",
      " 96%|█████████▋| 964/1000 [01:34<00:02, 12.68it/s]]\n",
      " 83%|████████▎ | 832/1000 [01:36<00:16,  9.93it/s]]\n",
      "100%|██████████| 1000/1000 [01:37<00:00, 14.95it/s]\n",
      " 67%|██████▋   | 668/1000 [01:37<00:31, 10.62it/s]]\n",
      " 60%|█████▉    | 595/1000 [01:38<00:39, 10.37it/s]]\n",
      " 61%|██████    | 607/1000 [01:39<00:34, 11.52it/s]]\n",
      " 92%|█████████▏| 916/1000 [01:40<00:05, 15.57it/s]]\n",
      " 80%|████████  | 804/1000 [01:41<00:15, 12.71it/s]]\n",
      " 86%|████████▌ | 859/1000 [01:42<00:11, 12.79it/s]]\n",
      " 83%|████████▎ | 834/1000 [01:42<00:10, 15.29it/s]]\n",
      " 80%|███████▉  | 797/1000 [01:44<00:14, 13.58it/s]]\n",
      " 87%|████████▋ | 869/1000 [01:44<00:08, 16.36it/s]]\n",
      " 96%|█████████▋| 963/1000 [01:44<00:02, 18.17it/s]]\n",
      " 85%|████████▍ | 849/1000 [01:44<00:09, 15.11it/s]]\n",
      " 89%|████████▉ | 891/1000 [01:45<00:05, 18.87it/s]]\n",
      "100%|██████████| 1000/1000 [01:46<00:00,  9.39it/s]\n",
      "\n",
      " 88%|████████▊ | 882/1000 [01:47<00:05, 23.02it/s]]\n",
      "100%|██████████| 1000/1000 [01:47<00:00,  9.29it/s]\n",
      "100%|██████████| 1000/1000 [01:48<00:00,  9.20it/s]\n",
      "100%|██████████| 1000/1000 [01:48<00:00,  9.19it/s]\n",
      "100%|██████████| 1000/1000 [01:49<00:00,  9.14it/s]\n",
      "100%|██████████| 1000/1000 [01:49<00:00,  9.12it/s]\n",
      "100%|██████████| 1000/1000 [01:49<00:00,  9.12it/s]\n",
      "100%|██████████| 1000/1000 [01:50<00:00,  9.08it/s]\n",
      "100%|██████████| 1000/1000 [01:50<00:00,  9.06it/s]\n",
      "100%|██████████| 1000/1000 [01:50<00:00,  9.02it/s]\n",
      "100%|██████████| 1000/1000 [01:52<00:00,  8.92it/s]\n",
      "100%|██████████| 1000/1000 [01:52<00:00,  8.85it/s]\n",
      "100%|██████████| 1000/1000 [01:53<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 s, sys: 2.03 s, total: 13.7 s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "j = main(pso, MAPPING_ALGORITHM.WORST_FIT_DECREASING, 0.8, 4, [GOAL.RESP_TIME, GOAL.WAIT_TIME])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T22:49:19.249312178Z",
     "start_time": "2023-07-01T22:47:25.113283259Z"
    }
   }
  }
 ]
}
